{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/3Bzpa1Cf/Laylj0Pj8rz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303a52274/Generative-AI/blob/main/GAI_WEEK_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.  Write Python code without using any libraries to find the value of x at which the\n",
        "function f(x) shown in equation (1) has minimum value. Consider Gradient Descent Algorithm.\n",
        "f (x) = 5x4 + 3x2 + 10"
      ],
      "metadata": {
        "id": "HzbFt50gD6yP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f_prime(x):\n",
        "    return 20 * x**3 + 6 * x\n",
        "\n",
        "def gradient_descent(initial_x, learning_rate, num_iterations):\n",
        "    x = initial_x\n",
        "    for _ in range(num_iterations):\n",
        "        grad = f_prime(x)\n",
        "        x = x - learning_rate * grad\n",
        "    return x\n",
        "initial_x = 0.5\n",
        "learning_rate = 0.01\n",
        "num_iterations = 1000\n",
        "min_x = gradient_descent(initial_x, learning_rate, num_iterations)\n",
        "print(\"The value of x at which f(x) has a minimum is:\", min_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlwFRl4ZBjxY",
        "outputId": "1c030292-eb24-4819-f480-e1ad3d7f3005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The value of x at which f(x) has a minimum is: 4.810419162406747e-28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Write Python code without using any libraries to find the value of x and y at which the\n",
        "function g(x,y) shown in equation (2) has minimum value. Consider Gradient Descent Algorithm.\n",
        "f (x) = 3x2 + 5e−y + 10"
      ],
      "metadata": {
        "id": "UFv6DA2TEDm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def partial_derivative_x(x, y):\n",
        "    return 6 * x\n",
        "\n",
        "def partial_derivative_y(x, y):\n",
        "    return -5 * (2.71828 ** -y)\n",
        "\n",
        "def gradient_descent(initial_x, initial_y, learning_rate, num_iterations):\n",
        "    x = initial_x\n",
        "    y = initial_y\n",
        "    for _ in range(num_iterations):\n",
        "        grad_x = partial_derivative_x(x, y)\n",
        "        grad_y = partial_derivative_y(x, y)\n",
        "        x = x - learning_rate * grad_x\n",
        "        y = y - learning_rate * grad_y\n",
        "    return x, y\n",
        "initial_x = 0.5\n",
        "initial_y = 0.5\n",
        "learning_rate = 0.01\n",
        "num_iterations = 1000\n",
        "min_x, min_y = gradient_descent(initial_x, initial_y, learning_rate, num_iterations)\n",
        "print(\"The values of x and y at which g(x, y) has a minimum are:\", min_x, min_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmHF544mBwhK",
        "outputId": "6f028427-df71-48e1-e9b1-f7aff06528e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The values of x and y at which g(x, y) has a minimum are: 6.711561962466847e-28 3.946138890954553\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Write Python code without using any libraries to find the value of x at which the\n",
        "sigmoid function z(x) shown in equation (3) has minimum value. Consider Gradient Descent\n",
        "Algorithm.\n",
        "z(x) = 1\n",
        "1 + e−x"
      ],
      "metadata": {
        "id": "XwrS0Tw4EcM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + 2.71828 ** -x)\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    sig = sigmoid(x)\n",
        "    return sig * (1 - sig)\n",
        "\n",
        "\n",
        "def gradient_descent(initial_x, learning_rate, num_iterations):\n",
        "    x = initial_x\n",
        "    for _ in range(num_iterations):\n",
        "        grad = sigmoid_derivative(x)\n",
        "        x = x - learning_rate * grad\n",
        "    return x\n",
        "\n",
        "initial_x = 0.5\n",
        "learning_rate = 0.01\n",
        "num_iterations = 1000\n",
        "min_x = gradient_descent(initial_x, learning_rate, num_iterations)\n",
        "print(\"The value of x at which z(x) has a minimum is:\", min_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrSATMQwBy1x",
        "outputId": "dfecfa05-2935-4768-e2ee-d4a02a184be3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The value of x at which z(x) has a minimum is: -1.6012961162961212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.Write Python code without using any libraries to find the value of optimal values of\n",
        "model parameters M and C such that the model’s Square Error Value shown in equation 4 will\n",
        "be minimum. It means model gives output close to expected output"
      ],
      "metadata": {
        "id": "aV7sexZREuPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_gradients(x, y_true, M, C):\n",
        "    y_pred = M * x + C\n",
        "    error = y_true - y_pred\n",
        "    gradient_M = -2 * x * error\n",
        "    gradient_C = -2 * error\n",
        "    return gradient_M, gradient_C\n",
        "\n",
        "\n",
        "def gradient_descent(x, y_true, initial_M, initial_C, learning_rate, num_iterations):\n",
        "    M = initial_M\n",
        "    C = initial_C\n",
        "    for _ in range(num_iterations):\n",
        "        total_gradient_M = 0\n",
        "        total_gradient_C = 0\n",
        "        for i in range(len(x)):\n",
        "            grad_M, grad_C = compute_gradients(x[i], y_true[i], M, C)\n",
        "            total_gradient_M += grad_M\n",
        "            total_gradient_C += grad_C\n",
        "        M = M - learning_rate * (total_gradient_M / len(x))\n",
        "        C = C - learning_rate * (total_gradient_C / len(x))\n",
        "    return M, C\n",
        "\n",
        "\n",
        "x = [1, 2, 3, 4, 5]\n",
        "y_true = [3, 7, 11, 15, 19]\n",
        "initial_M = 0.0\n",
        "initial_C = 0.0\n",
        "learning_rate = 0.01\n",
        "num_iterations = 1000\n",
        "optimal_M, optimal_C = gradient_descent(x, y_true, initial_M, initial_C, learning_rate, num_iterations)\n",
        "print(\"The optimal values of M and C are:\", optimal_M, optimal_C)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wN1dMcDCsQQ",
        "outputId": "c2dfa414-13b3-49d5-e410-19ba0181a8b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The optimal values of M and C are: 3.981660469673651 -0.9337884764204182\n"
          ]
        }
      ]
    }
  ]
}